<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Arctic Tracker API - Backend Architecture</title>
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 1400px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }
        
        h1, h2, h3 {
            color: #2c3e50;
        }
        
        h1 {
            text-align: center;
            border-bottom: 3px solid #3498db;
            padding-bottom: 20px;
            margin-bottom: 30px;
        }
        
        .section {
            background: white;
            padding: 30px;
            margin-bottom: 30px;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        
        .mermaid {
            text-align: center;
            margin: 20px 0;
        }
        
        .description {
            background: #e8f4f8;
            padding: 15px;
            border-radius: 5px;
            margin: 15px 0;
            border-left: 4px solid #3498db;
        }
        
        .code-block {
            background: #2c3e50;
            color: #ecf0f1;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
            font-family: 'Courier New', monospace;
            font-size: 14px;
            margin: 15px 0;
        }
        
        .feature-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }
        
        .feature-card {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 5px;
            border: 1px solid #dee2e6;
        }
        
        .feature-card h3 {
            margin-top: 0;
            color: #3498db;
        }
        
        .stats {
            display: flex;
            justify-content: space-around;
            flex-wrap: wrap;
            margin: 20px 0;
        }
        
        .stat-item {
            text-align: center;
            padding: 20px;
            background: #3498db;
            color: white;
            border-radius: 5px;
            margin: 10px;
            min-width: 150px;
        }
        
        .stat-number {
            font-size: 2em;
            font-weight: bold;
        }
        
        .stat-label {
            font-size: 0.9em;
            opacity: 0.9;
        }
    </style>
</head>
<body>
    <h1>ðŸŒŠ Arctic Tracker API - Backend Architecture</h1>
    
    <div class="section">
        <h2>System Overview</h2>
        <div class="description">
            The Arctic Tracker API is a comprehensive system for managing and analyzing CITES trade data for Arctic species. 
            It integrates multiple data sources, processes millions of trade records, and provides real-time access through 
            modern APIs.
        </div>
        
        <div class="stats">
            <div class="stat-item">
                <div class="stat-number">43</div>
                <div class="stat-label">Arctic Species</div>
            </div>
            <div class="stat-item">
                <div class="stat-number">5M+</div>
                <div class="stat-label">Trade Records</div>
            </div>
            <div class="stat-item">
                <div class="stat-number">1975-2024</div>
                <div class="stat-label">Data Coverage</div>
            </div>
            <div class="stat-item">
                <div class="stat-number">60-80%</div>
                <div class="stat-label">Storage Optimization</div>
            </div>
        </div>
    </div>

    <div class="section">
        <h2>Complete Architecture Diagram</h2>
        <div class="description">
            This diagram shows the complete data flow from external sources through the processing pipeline to client applications.
        </div>
        <div class="mermaid">
graph TB
    %% External Data Sources
    subgraph "External Data Sources"
        CITES[CITES Trade Database<br/>2GB+ CSV files]
        IUCN[IUCN Red List API v4<br/>Conservation Assessments]
        CMS[CMS Database<br/>Migratory Species Data]
        SCITE[Scite AI<br/>Scientific Research]
    end

    %% Data Processing Pipeline
    subgraph "Data Processing Pipeline"
        subgraph "Extraction Layer"
            EXT1[extract_species_trade_data.py<br/>Extract Arctic species from CITES]
            EXT2[rebuild_iucn_assessments.py<br/>Fetch IUCN conservation data]
            EXT3[process_cms_species_data.py<br/>Process CMS listings]
        end

        subgraph "Optimization Layer"
            OPT1[optimize_species_trade_json.py<br/>Normalize & compress data<br/>60-80% size reduction]
            OPT2[generate_trade_summaries.py<br/>Create pre-aggregated analytics]
        end

        subgraph "Validation Layer"
            VAL1[validate_before_load.py<br/>Data integrity checks]
            VAL2[verify_cms_data.py<br/>CMS data validation]
        end

        subgraph "Loading Layer"
            LOAD1[load_optimized_trade_data.py<br/>Batch insert with backups]
            LOAD2[upload_species_profiles.py<br/>AI-enhanced profiles]
        end
    end

    %% Supabase Backend
    subgraph "Supabase Backend"
        subgraph "PostgreSQL Database"
            subgraph "Core Tables"
                SPECIES[(species<br/>42 Arctic species)]
                TRADE[(cites_trade_records<br/>5+ million records)]
                IUCN_DB[(iucn_assessments<br/>Historical status)]
                CITES_DB[(cites_listings<br/>CITES appendices)]
                CMS_DB[(cms_listings<br/>CMS protection)]
                CATCH[(catch_records<br/>NAMMCO data)]
                SUMMARY[(species_trade_summary<br/>Pre-aggregated data)]
            end

            subgraph "Lookup Tables"
                LOOKUP[lookup_importers<br/>lookup_exporters<br/>lookup_terms<br/>lookup_units<br/>lookup_purposes<br/>lookup_sources]
            end

            subgraph "Support Tables"
                SUPPORT[common_names<br/>families<br/>glossary_terms<br/>article_summary_table]
            end
        end

        subgraph "Supabase Features"
            AUTH[Authentication<br/>Row Level Security]
            API[Auto-generated APIs<br/>REST & GraphQL]
            REALTIME[Real-time<br/>Subscriptions]
            STORAGE[File Storage<br/>Species Images]
        end
    end

    %% MCP Server Integration
    subgraph "MCP Server"
        MCP_TOOLS[MCP Arctic Tracker Server<br/>â”œâ”€â”€ list_arctic_species<br/>â”œâ”€â”€ search_species<br/>â”œâ”€â”€ get_cites_trade_data<br/>â”œâ”€â”€ get_conservation_status<br/>â”œâ”€â”€ get_species_threats<br/>â”œâ”€â”€ get_distribution_data<br/>â”œâ”€â”€ get_trade_summary<br/>â””â”€â”€ query_database]
    end

    %% Client Applications
    subgraph "Client Applications"
        WEB[Web Application<br/>React/Next.js]
        AI[AI Assistants<br/>Claude/ChatGPT]
        MOBILE[Mobile Apps<br/>iOS/Android]
        ANALYTICS[Analytics Tools<br/>Data Scientists]
    end

    %% Data Flow Connections
    CITES --> EXT1
    IUCN --> EXT2
    CMS --> EXT3
    SCITE --> LOAD2

    EXT1 --> OPT1
    EXT2 --> VAL1
    EXT3 --> VAL2

    OPT1 --> OPT2
    OPT2 --> VAL1

    VAL1 --> LOAD1
    VAL2 --> LOAD1

    LOAD1 --> TRADE
    LOAD1 --> SPECIES
    LOAD1 --> IUCN_DB
    LOAD1 --> CITES_DB
    LOAD1 --> CMS_DB
    LOAD2 --> SPECIES

    TRADE --> LOOKUP
    TRADE --> SUMMARY

    SPECIES --> IUCN_DB
    SPECIES --> CITES_DB
    SPECIES --> CMS_DB
    SPECIES --> TRADE
    SPECIES --> CATCH
    SPECIES --> SUPPORT

    API --> WEB
    API --> MOBILE
    API --> ANALYTICS
    MCP_TOOLS --> AI

    %% Supabase Internal Connections
    AUTH --> API
    REALTIME --> API
    STORAGE --> API

    %% MCP to Database
    MCP_TOOLS -.-> |Direct SQL Queries| SPECIES
    MCP_TOOLS -.-> |Direct SQL Queries| TRADE
    MCP_TOOLS -.-> |Direct SQL Queries| IUCN_DB

    classDef external fill:#f9f,stroke:#333,stroke-width:2px
    classDef processing fill:#bbf,stroke:#333,stroke-width:2px
    classDef database fill:#bfb,stroke:#333,stroke-width:2px
    classDef feature fill:#fbf,stroke:#333,stroke-width:2px
    classDef client fill:#ffb,stroke:#333,stroke-width:2px

    class CITES,IUCN,CMS,SCITE external
    class EXT1,EXT2,EXT3,OPT1,OPT2,VAL1,VAL2,LOAD1,LOAD2 processing
    class SPECIES,TRADE,IUCN_DB,CITES_DB,CMS_DB,CATCH,SUMMARY,LOOKUP,SUPPORT database
    class AUTH,API,REALTIME,STORAGE,MCP_TOOLS feature
    class WEB,AI,MOBILE,ANALYTICS client
        </div>
    </div>

    <div class="section">
        <h2>Data Flow Sequence</h2>
        <div class="description">
            This sequence diagram illustrates the step-by-step process of how data moves through the system from 
            external sources to client applications.
        </div>
        <div class="mermaid">
sequenceDiagram
    participant External as External Sources
    participant Extract as Extraction Scripts
    participant Optimize as Optimization Scripts
    participant Validate as Validation Scripts
    participant Load as Loading Scripts
    participant DB as Supabase Database
    participant API as Supabase API
    participant Client as Client Applications

    External->>Extract: Raw data (CSV, API)
    Extract->>Optimize: Extracted JSON files
    Optimize->>Validate: Normalized data
    Validate->>Load: Validated data
    Load->>DB: Batch inserts
    DB->>API: Auto-generated endpoints
    API->>Client: REST/GraphQL responses
    
    Note over DB: 5+ million trade records<br/>42 Arctic species<br/>Pre-aggregated summaries
    Note over API: Row Level Security<br/>Real-time subscriptions<br/>Built-in authentication
        </div>
    </div>

    <div class="section">
        <h2>Database Schema</h2>
        <div class="description">
            Entity relationship diagram showing the core database tables and their relationships.
        </div>
        <div class="mermaid">
erDiagram
    SPECIES ||--o{ CITES_TRADE_RECORDS : has
    SPECIES ||--o{ IUCN_ASSESSMENTS : has
    SPECIES ||--|| CMS_LISTINGS : has
    SPECIES ||--o{ COMMON_NAMES : has
    SPECIES ||--o{ CATCH_RECORDS : has
    SPECIES }|--|| FAMILIES : belongs_to
    
    CITES_TRADE_RECORDS }o--|| LOOKUP_IMPORTERS : uses
    CITES_TRADE_RECORDS }o--|| LOOKUP_EXPORTERS : uses
    CITES_TRADE_RECORDS }o--|| LOOKUP_TERMS : uses
    CITES_TRADE_RECORDS }o--|| LOOKUP_UNITS : uses
    CITES_TRADE_RECORDS }o--|| LOOKUP_PURPOSES : uses
    CITES_TRADE_RECORDS }o--|| LOOKUP_SOURCES : uses

    SPECIES {
        uuid id PK
        string taxon_id
        string scientific_name
        string taxonomic_authority
        uuid family_id FK
        string genus
        string species_epithet
        string iucn_category
        int population_trend
        jsonb conservation_measures
        jsonb habitat_info
        text ai_summary
    }

    CITES_TRADE_RECORDS {
        uuid id PK
        uuid species_id FK
        int year
        int importer_id FK
        int exporter_id FK
        float quantity
        int term_id FK
        int unit_id FK
        int purpose_id FK
        int source_id FK
    }

    IUCN_ASSESSMENTS {
        uuid id PK
        uuid species_id FK
        string assessment_id
        int year
        string category
        string criteria
        text rationale
    }
        </div>
    </div>

    <div class="section">
        <h2>Key Features</h2>
        <div class="feature-grid">
            <div class="feature-card">
                <h3>ðŸš€ Performance Optimizations</h3>
                <ul>
                    <li>Normalized data with lookup tables (60-80% storage reduction)</li>
                    <li>Pre-aggregated summaries for instant queries</li>
                    <li>Composite indexes on frequently queried columns</li>
                    <li>Full-text search capabilities</li>
                </ul>
            </div>
            
            <div class="feature-card">
                <h3>ðŸ”„ Data Pipeline Automation</h3>
                <ul>
                    <li>Automated extraction from multiple sources</li>
                    <li>Data validation and integrity checks</li>
                    <li>Batch processing for large datasets</li>
                    <li>Automatic backup creation</li>
                </ul>
            </div>
            
            <div class="feature-card">
                <h3>ðŸ”’ Security & Access Control</h3>
                <ul>
                    <li>Row Level Security (RLS) policies</li>
                    <li>Environment-based configuration</li>
                    <li>Service role keys for admin operations</li>
                    <li>Input validation and sanitization</li>
                </ul>
            </div>
            
            <div class="feature-card">
                <h3>ðŸ”Œ Integration Capabilities</h3>
                <ul>
                    <li>MCP server for AI assistant integration</li>
                    <li>Auto-generated REST and GraphQL APIs</li>
                    <li>Real-time data subscriptions</li>
                    <li>Direct SQL query access for advanced users</li>
                </ul>
            </div>
        </div>
    </div>

    <div class="section">
        <h2>Usage Examples</h2>
        
        <h3>Running the Data Pipeline</h3>
        <div class="code-block">
# 1. Extract species data from CITES
cd core
python extract_species_trade_data.py --mode full

# 2. Optimize the extracted data
python optimize_species_trade_json.py

# 3. Validate before loading
python validate_before_load.py

# 4. Load to database with backup
python load_optimized_trade_data.py --backup

# 5. Generate trade summaries
python generate_trade_summaries.py
        </div>
        
        <h3>API Endpoints</h3>
        <div class="code-block">
# Get all Arctic species with conservation status
GET /rest/v1/species?select=*,iucn_assessments(*),cites_listings(*)

# Get trade records for Polar Bear
GET /rest/v1/cites_trade_records?species_id=eq.{polar_bear_uuid}&year=gte.2020

# Get pre-aggregated trade summary
GET /rest/v1/species_trade_summary?species_id=eq.{species_uuid}
        </div>
        
        <h3>MCP Server Usage</h3>
        <div class="code-block">
// List endangered Arctic species
await mcp.list_arctic_species({
  conservation_status: "EN",
  class: "MAMMALIA"
});

// Search for species by name
await mcp.search_species({
  query: "polar bear",
  search_type: "common_name"
});

// Get trade data with filters
await mcp.get_cites_trade_data({
  species_id: "uuid",
  year: 2023,
  purpose: "T"  // Commercial trade
});
        </div>
    </div>

    <div class="section">
        <h2>Production Infrastructure</h2>
        <div class="description">
            <ul>
                <li><strong>Database</strong>: Supabase (PostgreSQL 15)</li>
                <li><strong>API</strong>: Auto-generated REST & GraphQL</li>
                <li><strong>File Storage</strong>: Supabase Storage for images</li>
                <li><strong>Authentication</strong>: Supabase Auth with RLS</li>
                <li><strong>Monitoring</strong>: Built-in Supabase dashboard</li>
                <li><strong>Backups</strong>: Automated daily backups</li>
            </ul>
        </div>
    </div>

    <script>
        mermaid.initialize({ 
            startOnLoad: true,
            theme: 'default',
            themeVariables: {
                primaryColor: '#3498db',
                primaryTextColor: '#fff',
                primaryBorderColor: '#2980b9',
                lineColor: '#5a5a5a',
                secondaryColor: '#e74c3c',
                tertiaryColor: '#f39c12'
            }
        });
    </script>
</body>
</html>